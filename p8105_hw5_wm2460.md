p8105_hw5_wm2460
================

## Problem 1

The code chunk below imports the data in individual spreadsheets
contained in `./data/zip_data/`. To do this, I create a dataframe that
includes the list of all files in that directory and the complete path
to each file. As a next step, I `map` over paths and import data using
the `read_csv` function. Finally, I `unnest` the result of `map`.

``` r
full_df = 
  tibble(
    files = list.files("data/zip_data/"),
    path = str_c("data/zip_data/", files)
  ) %>% 
  mutate(data = map(path, read_csv)) %>% 
  unnest()
```

The result of the previous code chunk isn’t tidy – data are wide rather
than long, and some important variables are included as parts of others.
The code chunk below tides the data using string manipulations on the
file, converting from wide to long, and selecting relevant variables.

``` r
tidy_df = 
  full_df %>% 
  mutate(
    files = str_replace(files, ".csv", ""),
    group = str_sub(files, 1, 3)) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "outcome",
    names_prefix = "week_") %>% 
  mutate(week = as.numeric(week)) %>% 
  select(group, subj = files, week, outcome)
```

Finally, the code chunk below creates a plot showing individual data,
faceted by group.

``` r
tidy_df %>% 
  ggplot(aes(x = week, y = outcome, group = subj, color = group)) + 
  geom_point() + 
  geom_path() + 
  facet_grid(~group)
```

<img src="p8105_hw5_wm2460_files/figure-gfm/unnamed-chunk-3-1.png" width="90%" />

This plot suggests high within-subject correlation – subjects who start
above average end up above average, and those that start below average
end up below average. Subjects in the control group generally don’t
change over time, but those in the experiment group increase their
outcome in a roughly linear way.

## Problem 2

``` r
homicides_df = read_csv("./data/homicide-data.csv")
```

    ## Rows: 52179 Columns: 12
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (9): uid, victim_last, victim_first, victim_race, victim_age, victim_sex...
    ## dbl (3): reported_date, lat, lon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

#### Describe the raw data

In the `homicides_df` dataset, there are 52179 observations and 12
variables. The variables in this dataset include uid, reported_date,
victim_last, victim_first, victim_race, victim_age, victim_sex, city,
state, lat, lon, disposition.

``` r
homicides_new = homicides_df %>% 
  janitor::clean_names() %>% 
  mutate(city_state = str_c(city, state, sep = "_"),
         status = 
           case_when(disposition == "Closed without arrest" ~ "unsolved",
                     disposition == "Open/No arrest" ~ "unsolved",
                     disposition == "Closed by arrest" ~ "resolved")) 

summarize_df = homicides_new %>% 
  group_by(city_state) %>% 
  summarize(total = n(),
            unsolved = sum(status == "unsolved")) 

summarize_df
```

    ## # A tibble: 51 × 3
    ##    city_state     total unsolved
    ##    <chr>          <int>    <int>
    ##  1 Albuquerque_NM   378      146
    ##  2 Atlanta_GA       973      373
    ##  3 Baltimore_MD    2827     1825
    ##  4 Baton Rouge_LA   424      196
    ##  5 Birmingham_AL    800      347
    ##  6 Boston_MA        614      310
    ##  7 Buffalo_NY       521      319
    ##  8 Charlotte_NC     687      206
    ##  9 Chicago_IL      5535     4073
    ## 10 Cincinnati_OH    694      309
    ## # … with 41 more rows

#### Using `prop.test` for Baltimore, MD

``` r
prop.test(summarize_df %>% filter(city_state == "Baltimore_MD") %>%
            pull(unsolved), 
          summarize_df %>% filter(city_state == "Baltimore_MD") %>%
            pull(total)) %>% 
  broom::tidy()
```

    ## # A tibble: 1 × 8
    ##   estimate statistic  p.value parameter conf.low conf.high method        alter…¹
    ##      <dbl>     <dbl>    <dbl>     <int>    <dbl>     <dbl> <chr>         <chr>  
    ## 1    0.646      239. 6.46e-54         1    0.628     0.663 1-sample pro… two.si…
    ## # … with abbreviated variable name ¹​alternative

``` r
# save the output of prop.test as an R object
prop.test(summarize_df %>% filter(city_state == "Baltimore_MD") %>%
            pull(unsolved), 
          summarize_df %>% filter(city_state == "Baltimore_MD") %>%
            pull(total)) %>% 
  broom::tidy() %>% 
  saveRDS(., "./data/Baltimore_prop_test.rds")
```

#### Using `prop.test` for each cities

``` r
all_cities = summarize_df %>% 
  mutate(prop_tests = map2(.x = unsolved, .y = total, ~ prop.test(x = .x, n = .y)),
         tidy_df = map(.x = prop_tests, ~ broom::tidy(.x))) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_df) %>% 
  select(city_state, estimate, conf.low, conf.high)

all_cities
```

    ## # A tibble: 51 × 4
    ##    city_state     estimate conf.low conf.high
    ##    <chr>             <dbl>    <dbl>     <dbl>
    ##  1 Albuquerque_NM    0.386    0.337     0.438
    ##  2 Atlanta_GA        0.383    0.353     0.415
    ##  3 Baltimore_MD      0.646    0.628     0.663
    ##  4 Baton Rouge_LA    0.462    0.414     0.511
    ##  5 Birmingham_AL     0.434    0.399     0.469
    ##  6 Boston_MA         0.505    0.465     0.545
    ##  7 Buffalo_NY        0.612    0.569     0.654
    ##  8 Charlotte_NC      0.300    0.266     0.336
    ##  9 Chicago_IL        0.736    0.724     0.747
    ## 10 Cincinnati_OH     0.445    0.408     0.483
    ## # … with 41 more rows

#### A plot that shows the estimates and CIs for each city

``` r
all_cities_plot = all_cities %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

all_cities_plot
```

<img src="p8105_hw5_wm2460_files/figure-gfm/plot-1.png" width="90%" />

## Problem 3

#### Set up the simulation

``` r
sim_1 = function(n = 30, mu = 0, sigma = 5) {
     x = rnorm(n, mean = mu, sd = sigma)
     t_test = t.test(x, conf.int = 0.95) %>% broom::tidy()
     
     t_test
}

p3_df = vector("list", 1000)

for (i in 1:1000) {
  p3_df[[i]] = sim_1()
}

p3_df %>% 
  bind_rows() %>% 
  head()
```

    ## # A tibble: 6 × 8
    ##   estimate statistic  p.value parameter conf.low conf.high method        alter…¹
    ##      <dbl>     <dbl>    <dbl>     <dbl>    <dbl>     <dbl> <chr>         <chr>  
    ## 1  -0.201    -0.204  0.840           29    -2.22     1.82  One Sample t… two.si…
    ## 2  -0.977    -1.02   0.318           29    -2.94     0.989 One Sample t… two.si…
    ## 3  -0.581    -0.616  0.543           29    -2.51     1.35  One Sample t… two.si…
    ## 4   0.300     0.365  0.718           29    -1.38     1.98  One Sample t… two.si…
    ## 5   0.0209    0.0256 0.980           29    -1.65     1.69  One Sample t… two.si…
    ## 6   2.39      3.67   0.000980        29     1.06     3.72  One Sample t… two.si…
    ## # … with abbreviated variable name ¹​alternative

#### Simulation for different mu

``` r
sim_2 = function(set){
  
  p3_df = vector("list", 1000)
  for (i in 1:1000) {
     p3_df[[i]] = sim_1(mu = set)
  }
  
  power = 
    p3_df %>% 
    bind_rows() %>% 
    janitor::clean_names() %>% 
    select(estimate, p_value) %>% 
    filter(p_value < 0.05) %>% 
    count()
  
  power
  
}

test_power =
  tibble(mus = c(0, 1, 2, 3, 4, 5, 6),
         reject_time = map(mus, sim_2)) %>%  
  unnest(reject_time) %>% 
  mutate(power = n/1000)
```

#### A plot between the power of the test and the true value of μ

``` r
power_plot = test_power %>% 
  ggplot(aes(x = mus, y = power)) +
  geom_point(aes(color = mus), size = 2) +
  geom_line(alpha = 0.3) +
  labs(x = "True value of μ",
       y = "Power of the test")

power_plot
```

<img src="p8105_hw5_wm2460_files/figure-gfm/power_plot-1.png" width="90%" />

From the plot, we can see clearly that the power of the test increase as
the true value of μ increase. Therefore, as the effect size (i.e., the
true value of μ) increase, power increases.

#### A plot showing the average estimate of μ^ and the true value of μ

``` r
sim_3 = function(n = 30, mu = 0, sigma = 5) {
     sim_data = tibble(x = rnorm(n, mean = mu, sd = sigma),)
     
     sim_t_test = t.test(pull(sim_data,x), conf.int = 0.95) %>% 
              broom::tidy() %>% 
              janitor::clean_names() %>% 
              select( p_value)
     
     sim_data %>% 
     summarize(mu_hat_all = mean(x),
               mu_hat_rej = case_when(
                 pull(sim_t_test, p_value) < 0.05 ~ mean(x),
                 pull(sim_t_test, p_value) >= 0.05 ~ as.numeric("")))
}

sim_4 = function(set){
  mu_hat = vector("list", 1000)
  for (i in 1:1000) {
     mu_hat[[i]] = sim_3(mu = set)
     }
  
  mu_hat %>% 
    bind_rows() %>% 
    summarize(all = mean(mu_hat_all, na.rm = TRUE),
              reject = mean(mu_hat_rej, na.rm = TRUE))
}

average_muhat =
  tibble(true_mu = c(0, 1, 2, 3, 4, 5, 6),
         muhat = map(true_mu, sim_4)) %>%  
  unnest(muhat) %>% 
  pivot_longer(all:reject,
               names_to = "samples",
               values_to = "average")

all_plot = average_muhat %>% 
  filter(samples == "all") %>% 
  ggplot(aes(x = true_mu, y = average)) +
  geom_point(size = 2) +
  geom_line()

all_plot
```

<img src="p8105_hw5_wm2460_files/figure-gfm/average_plot-1.png" width="90%" />

``` r
reject_plot = average_muhat %>% 
  filter(samples == "reject") %>% 
  ggplot(aes(x = true_mu, y = average)) +
  geom_point(size = 2) +
  geom_line()

reject_plot
```

<img src="p8105_hw5_wm2460_files/figure-gfm/average_plot-2.png" width="90%" />

``` r
together_plot = average_muhat %>% 
  ggplot(aes(x = true_mu, y = average, group = samples)) +
  geom_point(aes(color = samples), size = 2) +
  geom_line(alpha = 0.5)

together_plot
```

<img src="p8105_hw5_wm2460_files/figure-gfm/average_plot-3.png" width="90%" />

When the true mu is less than 4, the sample average of μ^ across tests
for which the null is rejected is not approximately equal to the true
value of μ. However, if the true mu is 4, 5, or 6, the sample average of
μ^ across tests for which the null is rejected is approximately equal to
the true value of μ.
